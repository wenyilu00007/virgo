<?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <include resource="org/springframework/boot/logging/logback/base.xml" />

    <springProperty scope="context" name="bootstrap.servers" source="zodiac.log.kafka.servers" />
    <property name="CONSOLE_LOG_PATTERN"
              value="%d{yyyy-MM-dd HH:mm:ss.SSS} ${LOG_LEVEL_PATTERN:-%5p}  [%X{X-B3-TraceId:-}] ${PID:- }  %-40.40logger{39}  %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}" />
    <!--value="%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr([${springAppName:-},%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-B3-ParentSpanId:-},%X{X-Span-Export:-}]){yellow} %clr(${PID:- }){magenta} %clr(-&#45;&#45;){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}" />-->

    <!-- 测试环境.开发环境使用默认的控制台输出，如果多个环境使用相同的配置，用多个使用逗号隔开. -->
    <springProfile name="test">
        <appender name="KafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
            <encoder class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
                <layout class="ch.qos.logback.classic.PatternLayout" >
                    <pattern>virgo-mail-${CONSOLE_LOG_PATTERN}</pattern>
                </layout>
                <!--<layout class="net.logstash.logback.layout.LogstashLayout" >-->
                    <!--<includeContext>true</includeContext>-->
                    <!--<includeCallerData>true</includeCallerData>-->
                    <!--<customFields>{"system":"virgo-mail"}</customFields>-->
                    <!--<fieldNames class="net.logstash.logback.fieldnames.ShortenedFieldNames"/>-->
                <!--</layout>-->
                <charset>UTF-8</charset>
            </encoder>
            <!--kafka topic 需要与配置文件里面的topic一致-->
            <topic>applog</topic>
            <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
            <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
            <!--<producerConfig>${bootstrap.servers}</producerConfig>-->
            <producerConfig>bootstrap.servers=10.39.251.26:9092,10.39.251.27:9092</producerConfig>
            <!-- use gzip to compress each batch of log messages. valid values: none, gzip, snappy  -->
            <producerConfig>compression.type=gzip</producerConfig>
        </appender>

        <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="KafkaAppender" />
        </appender>

        <!--输出到文件-->
        <property name="log.path" value="/opt/app/logs/virgo-mail/logback.log" />
        <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${log.path}</file>
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <fileNamePattern>virgo-mail-logback.%d{yyyy-MM-dd_HH}.log</fileNamePattern>
                <maxHistory>30</maxHistory>
                <totalSizeCap>1GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n</pattern>
            </encoder>
        </appender>
        <root>
            <level value="INFO" />
            <appender-ref ref="CONSOLE" />
            <appender-ref ref="FILE" />
            <appender-ref ref="ASYNC" />
        </root>
    </springProfile>

    <!-- 生产环境. -->
    <springProfile name="prod">
        <appender name="KafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
            <encoder class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
                <layout class="ch.qos.logback.classic.PatternLayout" >
                    <pattern>virgo-mail-${CONSOLE_LOG_PATTERN}</pattern>
                </layout>
                <!--<layout class="net.logstash.logback.layout.LogstashLayout" >-->
                    <!--<includeContext>true</includeContext>-->
                    <!--<includeCallerData>true</includeCallerData>-->
                    <!--<customFields>{"system":"virgo-mail"}</customFields>-->
                    <!--<fieldNames class="net.logstash.logback.fieldnames.ShortenedFieldNames"/>-->
                <!--</layout>-->
                <charset>UTF-8</charset>
            </encoder>
            <!--kafka topic 需要与配置文件里面的topic一致-->
            <topic>applog</topic>
            <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
            <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
            <!--<producerConfig>${bootstrap.servers}</producerConfig>-->
            <producerConfig>bootstrap.servers=10.30.20.27:9092,10.30.20.28:9092,10.30.20.29:9092</producerConfig>
            <!-- use gzip to compress each batch of log messages. valid values: none, gzip, snappy  -->
            <producerConfig>compression.type=gzip</producerConfig>
        </appender>

        <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="KafkaAppender" />
        </appender>

        <!--输出到文件-->
        <property name="log.path" value="/opt/app/logs/virgo-mail/logback.log" />
        <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${log.path}</file>
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <fileNamePattern>virgo-mail-logback.%d{yyyy-MM-dd}.log</fileNamePattern>
                <maxHistory>30</maxHistory>
                <totalSizeCap>1GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n</pattern>
            </encoder>
        </appender>
        <root>
            <level value="INFO" />
            <appender-ref ref="CONSOLE" />
            <appender-ref ref="FILE" />
            <appender-ref ref="ASYNC" />
        </root>
    </springProfile>

    <!-- 香港生产环境. -->
    <springProfile name="hkprod">
        <appender name="KafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
            <encoder class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
                <layout class="ch.qos.logback.classic.PatternLayout" >
                    <pattern>virgo-mail-${CONSOLE_LOG_PATTERN}</pattern>
                </layout>
                <!--<layout class="net.logstash.logback.layout.LogstashLayout" >-->
                <!--<includeContext>true</includeContext>-->
                <!--<includeCallerData>true</includeCallerData>-->
                <!--<customFields>{"system":"virgo-mail"}</customFields>-->
                <!--<fieldNames class="net.logstash.logback.fieldnames.ShortenedFieldNames"/>-->
                <!--</layout>-->
                <charset>UTF-8</charset>
            </encoder>
            <!--kafka topic 需要与配置文件里面的topic一致-->
            <topic>applog</topic>
            <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
            <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
            <!--<producerConfig>${bootstrap.servers}</producerConfig>-->
            <producerConfig>bootstrap.servers=10.31.20.27:9092,10.31.20.28:9092,10.31.20.29:9092</producerConfig>
            <!-- use gzip to compress each batch of log messages. valid values: none, gzip, snappy  -->
            <producerConfig>compression.type=gzip</producerConfig>
        </appender>

        <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="KafkaAppender" />
        </appender>

        <!--输出到文件-->
        <property name="log.path" value="/opt/app/logs/virgo-mail/logback.log" />
        <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${log.path}</file>
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <fileNamePattern>virgo-mail-logback.%d{yyyy-MM-dd}.log</fileNamePattern>
                <maxHistory>30</maxHistory>
                <totalSizeCap>1GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n</pattern>
            </encoder>
        </appender>
        <root>
            <level value="INFO" />
            <appender-ref ref="CONSOLE" />
            <appender-ref ref="FILE" />
            <appender-ref ref="ASYNC" />
        </root>
    </springProfile>

</configuration>